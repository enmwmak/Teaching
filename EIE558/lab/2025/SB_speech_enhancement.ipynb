{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enmwmak/Teaching/blob/main/EIE558/lab/2025/SB_speech_enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRm3Be4lgM4b"
      },
      "source": [
        "# Speech Enhancement Based on SpeechBrain\n",
        "\n",
        "## 1. Objectives\n",
        "This lab exercise enables you to learn how to use the pre-trained speech models from SpeechBrain to reduce the noise in speech files. You can compare the speech quality of the denoised (enhanced) speech subjectively (through listening tests) and objectively (through Short-Time Objective Intelligibility (STOI)).  \n",
        "\n",
        "## 2. Prerequisites\n",
        "Before starting this lab, you should learn the <a href=\"https://speechbrain.readthedocs.io/en/v1.0.3/tutorials/basics.html\">basics</a> of SpeechBrain and read the <a href=\"https://speechbrain.readthedocs.io/en/v1.0.3/tutorials/tasks/speech-enhancement-from-scratch.html\">tutorial</a> on speech enhancement. After knowing what SpeechBrain is about and how it performs speech enhancement, you need to read the procedure for using its <a href=\"https://speechbrain.readthedocs.io/en/v1.0.3/API/speechbrain.inference.enhancement.html\">pre-trained models</a> for speech enhancement. You may also want to read the paper on <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5713237\">STOI</a>.\n",
        "\n",
        "##3. Submission\n",
        "Write a report, convert it to PDF, and submit it to Blackboard before the deadline specified in Blackboard. Your report may contain the following:\n",
        "<ol type=\"a\">\n",
        "  <li>Discussions on your observations, e.g., what kind of noise is difficult for the pre-trained model</li>\n",
        "  <li>Waveforms and spectrograms of noisy speech corrupted by different noise types</li>\n",
        "  <li>Waveforms and spectrograms of denoised speech enhanced by different pre-trained models</li>\n",
        "  <li>Comparison between spectral subtraction and deep learning based speech enhancement\n",
        "  <li>The STOI scores of the noisy and enhanced speech</li>\n",
        "\n",
        "</ol>\n",
        "\n",
        "##4. Prepare Colab Environment\n",
        "Colab runs on browsers. You need a Google account to use Colab. If you do not have one, visit https://support.google.com/mail/answer/56256?hl=en.\n",
        "\n",
        "Display the Google Drive page (https://drive.google.com/drive/my-drive) in your browser. Use the “+ New” button on the left panel to create a directory structure in your Google Drive as follows: \"My Drive/Learning/EIE558/Lab1\"\n",
        "\n",
        "##5. Procedure\n",
        "1. Upload this .ipynb file to your Google Drive under the \"My Drive/Learning/EIE558/Lab1\" folder.\n",
        "2. Create a folder \"My Drive/Learning/EIE558/Lab1/audio\".\n",
        "3. Download the .wav files in https://github.com/enmwmak/Teaching/tree/main/EIE558/lab/2025 and upload them to your \"My Drive/Learning/EIE558/Lab1/audio\" folder in Google Drive.\n",
        "3. Execute the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsI3FwitIV4C"
      },
      "outputs": [],
      "source": [
        "# Check Python version (This script works on Python 3.12, Torch 2.8, and Torchaudio 2.8)\n",
        "!python --version\n",
        "import torch\n",
        "import torchaudio\n",
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FClKBynOIi3S"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive and change to the Lab1 folder.\n",
        "# You should perform this step after the expiration of each session.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/Lab1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMzAUrHnJtln"
      },
      "outputs": [],
      "source": [
        "# Installing SpeechBrain and STOI via pip.\n",
        "# You should perform this step after the expiration of each Colab session.\n",
        "BRANCH = 'develop'\n",
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "!pip install pystoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1zefBeaRKhPs"
      },
      "outputs": [],
      "source": [
        "# Clone SpeechBrain repository to your Lab1 folder.\n",
        "# Skip this step if you have done this before as SpeechBrain has been installed on your Lab1 folder\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/Lab1\n",
        "!git clone https://github.com/speechbrain/speechbrain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA9hxrvLRGcx"
      },
      "outputs": [],
      "source": [
        "# Define a function that plots the waveforms and spectrograms of noisy and enhanced speech\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def show_wav_and_spec(wavfile):\n",
        "  waveform, srate = librosa.load(wavfile, sr=librosa.get_samplerate(wavfile))\n",
        "  n_samples = len(waveform)\n",
        "  frm_size = int(0.032 * srate)       # 32ms per frame\n",
        "  frm_shift = int(0.01 * srate)       # 100Hz frame rate\n",
        "  n_fft = n_samples if (n_samples < frm_size) else frm_size\n",
        "\n",
        "  # Compute magnitude spectrogram\n",
        "  magspec = abs(librosa.stft(y=waveform, n_fft=frm_size, hop_length=frm_shift))\n",
        "\n",
        "  # Plot spectrogram and waveform\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.subplot(211)\n",
        "  librosa.display.specshow(librosa.amplitude_to_db(magspec), sr=srate, y_axis='linear',\n",
        "                           hop_length=frm_shift)\n",
        "  plt.subplot(313)\n",
        "  librosa.display.waveshow(waveform, sr=srate, offset=0)\n",
        "  plt.margins(x=0)\n",
        "  plt.show()\n",
        "\n",
        "  display(Audio(wavfile, autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H0ekE-RLksG"
      },
      "outputs": [],
      "source": [
        "# Download and use a spectral-masking based pre-trained model to enhance speech\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/Lab1/speechbrain/templates/enhancement\n",
        "import torch\n",
        "from speechbrain.inference.enhancement import SpectralMaskEnhancement\n",
        "\n",
        "# Model is downloaded from the speechbrain HuggingFace repo\n",
        "enhancer = SpectralMaskEnhancement.from_hparams(source=\"speechbrain/metricgan-plus-voicebank\",\n",
        "                                                savedir=\"tmpdir1\",)\n",
        "enhanced = enhancer.enhance_file(\"../../../audio/noisyspeech16k.wav\", output_filename=\"../../../audio/enhanced1.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3clyK-xbid9"
      },
      "outputs": [],
      "source": [
        "# Display the spectrogram and waveform of the noisy speech file and play the audio file\n",
        "show_wav_and_spec(\"../../../audio/noisyspeech16k.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq0srxxcfvv2"
      },
      "outputs": [],
      "source": [
        "# Display the spectrogram and waveform of the enhanced speech file and play the audio file\n",
        "show_wav_and_spec(\"../../../audio/enhanced1.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCGRKUgSVKGS"
      },
      "outputs": [],
      "source": [
        "# Download and use another spectral-based pre-trained SE model to enhance speech\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/Lab1/speechbrain/templates/enhancement\n",
        "\n",
        "from speechbrain.inference.enhancement import WaveformEnhancement\n",
        "# Model is downloaded from the speechbrain HuggingFace repo\n",
        "enhancer = WaveformEnhancement.from_hparams(source=\"speechbrain/mtl-mimic-voicebank\",\n",
        "                                            savedir=\"tmpdir2\",)\n",
        "enhanced = enhancer.enhance_file(\"../../../audio/noisyspeech16k.wav\", output_filename=\"../../../audio/enhanced2.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqG7tzQ2fXa3"
      },
      "outputs": [],
      "source": [
        "# Display the spectrogram and waveform of the enhanced speech file and play the audio file\n",
        "show_wav_and_spec(\"../../../audio/enhanced2.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform objective evaluation based on STOI\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "from pystoi.stoi import stoi\n",
        "import numpy as np\n",
        "clean_wav = read_audio(\"../../../audio/cleanspeech16k.wav\")\n",
        "noisy_wav = read_audio(\"../../../audio/noisyspeech16k.wav\")\n",
        "enhan_wav = read_audio(\"../../../audio/enhanced2.wav\")\n",
        "num_smps = np.min([clean_wav.shape[0], noisy_wav.shape[0], enhan_wav.shape[0]])\n",
        "clean_wav = clean_wav[:num_smps]\n",
        "noisy_wav = noisy_wav[:num_smps]\n",
        "enhan_wav = enhan_wav[:num_smps]\n",
        "stoi_clean = stoi(clean_wav.numpy(), clean_wav.numpy(), 16000)\n",
        "stoi_noisy = stoi(clean_wav.numpy(), noisy_wav.numpy(), 16000)\n",
        "stoi_enhan = stoi(clean_wav.numpy(), enhan_wav.numpy(), 16000)\n",
        "print(f\"The STOI score of clean speech: {stoi_clean:.3f}\")\n",
        "print(f\"The STOI score of noisy speech: {stoi_noisy:.3f}\")\n",
        "print(f\"The STOI score of enhan speech: {stoi_enhan:.3f}\")"
      ],
      "metadata": {
        "id": "57b5pGcoyhpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y9Psax3n_Gp"
      },
      "outputs": [],
      "source": [
        "# Adding different types of noise to clean speech and save the noisy speech\n",
        "# as \"Lab1/audio/speech+noise.wav\"\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/Lab1/audio\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "snr_db = 0.0  # SNR in dB\n",
        "speech, _ = torchaudio.load(\"./cleanspeech16k.wav\")\n",
        "noise, _ = torchaudio.load(\"./machinegun.wav\")\n",
        "noise = noise[:, : speech.shape[1]]\n",
        "noisy_speech = F.add_noise(speech, noise, snr=torch.tensor([snr_db]))\n",
        "torchaudio.save(\"./speech+noise.wav\", noisy_speech, sample_rate=16000, format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1rtYpd0OZYI"
      },
      "outputs": [],
      "source": [
        "# Play the created noisy speech file\n",
        "# Display the spectrogram and waveform of the noisy speech file and play the audio file\n",
        "show_wav_and_spec(\"./speech+noise.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6zPYEFXO0nH"
      },
      "outputs": [],
      "source": [
        "# Download and use an end-to-end pre-trained model to enhance speech\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/Lab1/speechbrain/templates/enhancement\n",
        "\n",
        "from speechbrain.inference.enhancement import WaveformEnhancement\n",
        "# Model is downloaded from the speechbrain HuggingFace repo\n",
        "enhancer = WaveformEnhancement.from_hparams(source=\"speechbrain/mtl-mimic-voicebank\",\n",
        "                                            savedir=\"tmpdir2\",)\n",
        "enhanced = enhancer.enhance_file(\"../../../audio/speech+noise.wav\", output_filename=\"../../../audio/enhanced2.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5yBnhUFPKmE"
      },
      "outputs": [],
      "source": [
        "# Display the spectrogram and waveform of the enhanced speech file and play the audio file\n",
        "show_wav_and_spec(\"../../../audio/enhanced2.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciZrmYWjc7F5"
      },
      "source": [
        "### Code for Spectral Subtraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcW75xunc3jD"
      },
      "outputs": [],
      "source": [
        "def specsub(y, frame_size, frame_shift, sr=16000):\n",
        "    Y = librosa.stft(y, n_fft=frame_size, hop_length=frame_shift)     # Short-time Fourier transform\n",
        "    Ymag= np.abs(Y)         # Get magnitude (spectrogram)\n",
        "    Ypha= np.angle(Y)       # Get phase\n",
        "\n",
        "    # Assume that the beginning of the speech file contains noise only and get its average noise spectrum\n",
        "    noise_dur = 0.5             # Duration at the beginning of the file considered as noise\n",
        "    alpha = 2                   # Over-subtraction factor\n",
        "    noise_mag = Ymag[:, 0:int(noise_dur*sr/frame_shift)]\n",
        "    mean_noise_mag = np.mean(noise_mag, axis=1)\n",
        "    Xmag = Ymag - alpha * mean_noise_mag.reshape((mean_noise_mag.shape[0],1))\n",
        "\n",
        "    # Implement |Y(w) - B(w)| so that all negative values are set to 0\n",
        "    mask = (Xmag > 0).astype(int)\n",
        "    Xmag = Xmag * mask\n",
        "\n",
        "    # Convert to complex number using the phase information of noisy speech. Then, convert to time domain using ISTFT\n",
        "    Y = Xmag * np.exp(1.0j* Ypha)\n",
        "    y = librosa.istft(Y, n_fft=frame_size, hop_length=frame_shift)\n",
        "    return y, Y, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3MUfmkJdp8b"
      },
      "outputs": [],
      "source": [
        "# Load the noisy speech and perform spectral subtraction\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/Lab1\n",
        "frame_size = 512\n",
        "frame_shift = 64\n",
        "y, sr = librosa.load(\"audio/noisyspeech16k.wav\", sr=None, mono=True) # keep native sr (sampling rate) and trans into mono\n",
        "x, X, mask = specsub(y, frame_size=frame_size, frame_shift=frame_shift, sr=sr)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_Tn1KlDemuv"
      },
      "outputs": [],
      "source": [
        "# Function for plotting speech signal and its spectrogram\n",
        "def plot_speech(x, sr=8000, frm_len=512, hop_len=256):\n",
        "    X = librosa.amplitude_to_db(np.abs(librosa.stft(x, n_fft=frm_len, hop_length=hop_len)), ref=np.max)  # STFT of x\n",
        "    _, ax = plt.subplots(nrows=2, sharex=True, figsize=(8,4))\n",
        "    librosa.display.waveshow(x, sr=sr, ax=ax[0])\n",
        "    librosa.display.specshow(X, sr=sr, n_fft=frm_len, hop_length=hop_len, x_axis='time', y_axis='linear', ax=ax[1])\n",
        "    display(Audio(x, rate=sr, autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NErD_4b-edKD"
      },
      "outputs": [],
      "source": [
        "# Plot noisy speech\n",
        "plot_speech(y, sr=16000, frm_len=frame_size, hop_len=frame_shift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6GfBUMAf4-I"
      },
      "outputs": [],
      "source": [
        "# Plot denoised speech\n",
        "plot_speech(x, sr=16000, frm_len=frame_size, hop_len=frame_shift)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jix2wS5ujzAN"
      },
      "source": [
        "## References\n",
        "1. Fu, Szu-Wei, et al. \"Metricgan: Generative adversarial networks based black-box metric scores optimization for speech enhancement.\" International Conference on Machine Learning. PmLR, 2019.\n",
        "2. Fu, Szu-Wei, et al. \"Metricgan+: An improved version of metricgan for speech enhancement.\" arXiv preprint arXiv:2104.03538 (2021).\n",
        "3. Bagchi, Deblin, et al. \"Spectral feature mapping with mimic loss for robust speech recognition.\" 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018.\n",
        "4. Taal, Cees H., et al. \"An algorithm for intelligibility prediction of time–frequency weighted noisy speech.\" IEEE Transactions on audio, speech, and language processing 19.7 (2011): 2125-2136.\n",
        "5. Rix, Antony W., et al. \"Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs.\" 2001 IEEE international conference on acoustics, speech, and signal processing. Proceedings (Cat. No. 01CH37221). Vol. 2. IEEE, 2001."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZSv74hybIiGEZVPYSoFbR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}