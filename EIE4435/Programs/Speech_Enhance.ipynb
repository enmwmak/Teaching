{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enmwmak/Teaching/blob/main/EIE4435/Programs/Speech_Enhance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbNC_C1o_8jS"
      },
      "source": [
        "### This script implements a simple spectral subtraction algorithm. After setting the variables, you may click \"Runtime > Run all\" (if you use Colab) or click the \"Run All\" button (if you use Visual Studio Code) to run all cells in one operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZU3apa9_8jT"
      },
      "source": [
        "## **Procedures**\n",
        "1. Read the codes in this .ipynb file to understand how they work.\n",
        "1. Run all cells. Listen to the audio of (1) the noisy speech and (2) the denoised speech.\n",
        "1. Modify the variable '*alpha*' to see its effect on the denoised speech.\n",
        "1. Try other speech files and repeat Steps 2 and 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czmMtgKi_8jT"
      },
      "source": [
        "## **Answer the following questions**\n",
        "1. Identify the regions in the spectrogram of the denoised speech that correspond to the musical noise.\n",
        "1. Explain why spectral subtraction causes musical noise in the denoised speech.\n",
        "1. Identify the artifact and explain why such artifact exists when '*alpha*' is very large, say *alpha*=3'.\n",
        "1. Explain why adding a noise floor to the denoised signal can help alleviate the artifact in Step 3.\n",
        "1. Will adding a small amount of background noise to the denoised signal help alleviating the musical noise? Try it by modifying the program.\n",
        "1. Explain why spectral subraction is not good at removing the machine-gun noise.\n",
        "1. Explain why spectral subtraction will not cause musical noise in the enhanced speech if the SNR is very high.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f65Ul-YV_8jU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfKIqZom_8jU"
      },
      "outputs": [],
      "source": [
        "# Define some variables and constants\n",
        "use_colab = True            # Set to false if you use IDE such as Visual Studio Code\n",
        "infile = '../AudioFiles/noisy_speech2.wav'\n",
        "alpha = 2                   # Over-subtraction factor\n",
        "frame_size = 512\n",
        "frame_shift = 64\n",
        "noise_dur = 0.5             # Duration at the beginning of file considered as noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSOSrj9T_8jU"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive and create a folder for the lab exercise\n",
        "if use_colab == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  !mkdir -p /content/drive/MyDrive/Learning/EIE4435/Programs\n",
        "  %cd /content/drive/MyDrive/Learning/EIE4435/Programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_w-63MI_8jV"
      },
      "outputs": [],
      "source": [
        "# Function for plotting speech signal and its spectrogram\n",
        "def plot_speech(x, sr=8000, frm_len=512, hop_len=256):\n",
        "    X = librosa.amplitude_to_db(np.abs(librosa.stft(x, n_fft=frm_len, hop_length=hop_len)), ref=np.max)  # STFT of x\n",
        "    _, ax = plt.subplots(nrows=2, sharex=True, figsize=(8,4))\n",
        "    librosa.display.waveshow(x, sr=sr, ax=ax[0])\n",
        "    librosa.display.specshow(X, sr=sr, n_fft=frm_len, hop_length=hop_len, x_axis='time', y_axis='linear', ax=ax[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk3VNci3_8jV"
      },
      "outputs": [],
      "source": [
        "def specsub(y, frame_size, frame_shift, sr=8000):\n",
        "    Y = librosa.stft(y, n_fft=frame_size, hop_length=frame_shift)     # Short-time Fourier transform\n",
        "    Ymag= np.abs(Y)         # Get magnitude (spectrogram)\n",
        "    Ypha= np.angle(Y)       # Get phase\n",
        "\n",
        "    # Assume that the beginning of the speech file contains noise only and get its average noise spectrum\n",
        "    noise_mag = Ymag[:, 0:int(noise_dur*sr/frame_shift)]\n",
        "    mean_noise_mag = np.mean(noise_mag, axis=1)\n",
        "    Xmag = Ymag - alpha * mean_noise_mag.reshape((mean_noise_mag.shape[0],1))\n",
        "\n",
        "    # Implement |Y(w) - B(w)| so that all negative values are set to 0\n",
        "    mask = (Xmag > 0).astype(int)\n",
        "    Xmag = Xmag * mask\n",
        "\n",
        "    # Convert to complex number using the phase information of noisy speech. Then, convert to time domain using ISTFT\n",
        "    Y = Xmag * np.exp(1.0j* Ypha)\n",
        "    y = librosa.istft(Y, n_fft=frame_size, hop_length=frame_shift)\n",
        "    return y, Y, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrxYCfeN_8jV"
      },
      "outputs": [],
      "source": [
        "# Load the noisy speech and perform spectral subtraction\n",
        "y, sr = librosa.load(infile, sr=None, mono=True) # keep native sr (sampling rate) and trans into mono\n",
        "x, X, mask = specsub(y, frame_size=frame_size, frame_shift=frame_shift, sr=sr)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta1MfL4n_8jW"
      },
      "outputs": [],
      "source": [
        "# Original noisy speech\n",
        "plot_speech(y, sr=sr, frm_len=frame_size, hop_len=frame_shift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdq6EKIN_8jW"
      },
      "outputs": [],
      "source": [
        "# Denoised speech\n",
        "plot_speech(x, sr=sr, frm_len=frame_size, hop_len=frame_shift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_saU_uj_8jW"
      },
      "outputs": [],
      "source": [
        "# Plot the mask to show the frequencies and frames at which the spectral components (in white)\n",
        "# become negative after subtraction.\n",
        "plt.figure(figsize=(8,2))\n",
        "librosa.display.specshow(1-mask, sr=sr, n_fft=frame_size, hop_length=frame_shift, x_axis='time', y_axis='linear')\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa_v--dE_8jW"
      },
      "outputs": [],
      "source": [
        "# Listen to the noisy speech\n",
        "Audio(data=y, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loivjDIR_8jW"
      },
      "outputs": [],
      "source": [
        "# Listen to the denoised speech\n",
        "Audio(data=x, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eBa4lD7_8jW"
      },
      "source": [
        "Add non-stationary noise to clean a speech file to create a noisy speech file. Then, apply spectral subtraction to denoise the noisy speech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhuntbDX_8jX"
      },
      "outputs": [],
      "source": [
        "# Load clean speech and noise files\n",
        "from itertools import cycle, islice\n",
        "clean_speech_file = '../AudioFiles/clean_speech.wav'\n",
        "noise_file = '../AudioFiles/machine-gun.mp3'\n",
        "clean, sr = librosa.load(clean_speech_file, sr=None, mono=True) # keep native sr (sampling rate) and trans into mono\n",
        "noise, fs = librosa.load(noise_file, sr=None, mono=True)\n",
        "noise = librosa.resample(noise, orig_sr=fs, target_sr=sr)\n",
        "noise = np.array(list(islice(cycle(noise), clean.shape[0])))\n",
        "y = clean + 0.2*noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liohtYvZ_8jX"
      },
      "outputs": [],
      "source": [
        "# Perform spectral subtraction\n",
        "x, X, mask = specsub(y, frame_size=frame_size, frame_shift=frame_shift, sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q8A_C2x_8jX"
      },
      "outputs": [],
      "source": [
        "plot_speech(y, frm_len=frame_size, hop_len=frame_shift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPDDKJD4_8jX"
      },
      "outputs": [],
      "source": [
        "# Denoised speech\n",
        "plot_speech(x, frm_len=frame_size, hop_len=frame_shift)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Coq4UHm_8jX"
      },
      "outputs": [],
      "source": [
        "# Listen to the noisy speech\n",
        "Audio(data=y, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeSV4AlB_8jX"
      },
      "outputs": [],
      "source": [
        "# Listen to the denoised speech\n",
        "Audio(data=x, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the mask to show the frequencies and frames at which the spectral components (in white)\n",
        "# become negative after subtraction.\n",
        "plt.figure(figsize=(8,2))\n",
        "librosa.display.specshow(1-mask, sr=sr, n_fft=frame_size, hop_length=frame_shift, x_axis='time', y_axis='linear')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "hmy5ROMKCueU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DNN-based Speech Enhancement**\n",
        "**<font color=\"red\">This part is optional. Conduct this part if you want to learn more. You do not need to put the results of this part in your report</font>.**\n",
        "\n",
        "This part enables you to learn how to use the pre-trained speech models from SpeechBrain to reduce the noise in speech files. You can compare the speech quality of the denoised (enhanced) speech subjectively (through listening tests) and objectively (through Short-Time Objective Intelligibility (STOI)).\n",
        "\n",
        "Before starting this lab, you should learn the <a href=\"https://speechbrain.readthedocs.io/en/v1.0.3/tutorials/basics.html\">basics</a> of SpeechBrain and read the <a href=\"https://speechbrain.readthedocs.io/en/v1.0.3/tutorials/tasks/speech-enhancement-from-scratch.html\">tutorial</a> on speech enhancement. After knowing what SpeechBrain is about and how it performs speech enhancement, you need to read the procedure for using its <a href=\"https://speechbrain.readthedocs.io/en/v1.0.3/API/speechbrain.inference.enhancement.html\">pre-trained models</a> for speech enhancement. You may also want to read the paper on <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5713237\">STOI</a>.\n",
        "\n"
      ],
      "metadata": {
        "id": "MJ9iq1ZQ8bGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Python version (This script works on Python 3.12, Torch 2.8, and Torchaudio 2.8)\n",
        "!python --version\n",
        "import torch\n",
        "import torchaudio\n",
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)"
      ],
      "metadata": {
        "id": "ram7vIrr8vRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing SpeechBrain and STOI via pip.\n",
        "# You should perform this step after the expiration of each Colab session.\n",
        "BRANCH = 'develop'\n",
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "!pip install pystoi"
      ],
      "metadata": {
        "id": "E05jbABR-DOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone SpeechBrain repository to your folder.\n",
        "# Skip this step if you have done this before as SpeechBrain has been installed on your folder\n",
        "%cd /content/drive/MyDrive/Learning/EIE4435\n",
        "!git clone https://github.com/speechbrain/speechbrain/"
      ],
      "metadata": {
        "id": "vIThpIp_-ILo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA9hxrvLRGcx"
      },
      "outputs": [],
      "source": [
        "# Define a function that plots the waveforms and spectrograms of noisy and enhanced speech\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def show_wav_and_spec(wavfile):\n",
        "  waveform, srate = librosa.load(wavfile, sr=librosa.get_samplerate(wavfile))\n",
        "  n_samples = len(waveform)\n",
        "  frm_size = int(0.032 * srate)       # 32ms per frame\n",
        "  frm_shift = int(0.01 * srate)       # 100Hz frame rate\n",
        "  n_fft = n_samples if (n_samples < frm_size) else frm_size\n",
        "\n",
        "  # Compute magnitude spectrogram\n",
        "  magspec = abs(librosa.stft(y=waveform, n_fft=frm_size, hop_length=frm_shift))\n",
        "\n",
        "  # Plot spectrogram and waveform\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.subplot(211)\n",
        "  librosa.display.specshow(librosa.amplitude_to_db(magspec), sr=srate, y_axis='linear',\n",
        "                           hop_length=frm_shift)\n",
        "  plt.subplot(313)\n",
        "  librosa.display.waveshow(waveform, sr=srate, offset=0)\n",
        "  plt.margins(x=0)\n",
        "  plt.show()\n",
        "\n",
        "  display(Audio(wavfile, autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H0ekE-RLksG"
      },
      "outputs": [],
      "source": [
        "# Download and use a spectral-based pre-trained SE model to enhance speech\n",
        "%cd /content/drive/MyDrive/Learning/EIE4435/speechbrain/templates/enhancement\n",
        "\n",
        "from speechbrain.inference.enhancement import WaveformEnhancement\n",
        "# Model is downloaded from the speechbrain HuggingFace repo\n",
        "enhancer = WaveformEnhancement.from_hparams(source=\"speechbrain/mtl-mimic-voicebank\",\n",
        "                                            savedir=\"tmpdir2\",)\n",
        "enhanced = enhancer.enhance_file(\"../../../AudioFiles/noisy_speech2.wav\", output_filename=\"../../../AudioFiles/denoised_speech2.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the spectrogram and waveform of the noisy speech file and play the audio file\n",
        "show_wav_and_spec(\"../../../AudioFiles/noisy_speech2.wav\")"
      ],
      "metadata": {
        "id": "C61y5cXfDr6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the spectrogram and waveform of the enhanced speech file and play the audio file\n",
        "show_wav_and_spec(\"../../../AudioFiles/denoised_speech2.wav\")"
      ],
      "metadata": {
        "id": "wymHpOGXEjMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "3Sq2foXS8RVY"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}