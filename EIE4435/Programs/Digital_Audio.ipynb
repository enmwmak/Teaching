{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enmwmak/Teaching/blob/main/EIE4435/Programs/Digital_Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt6B-FSBYief"
      },
      "source": [
        "### This script demonstrates how dithering can be applied to low-amplitude signals that are vulnerable to quantization error. After setting the variables, you may click \"Runtime > Run all\" (if you use Colab) or click the \"Run All\" button (if you use Visual Studio Code) to run all cells in one operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij4C1BDGwWVy"
      },
      "source": [
        "## Procedures\n",
        "1. Read the codes in this .ipynb file to understand how they work.\n",
        "1. set *use_colab* to True if you use Google Colab; otherwise, set it to False.\n",
        "1. Set *source* to 'tone'.   \n",
        "1. Run all cells. Listen to the audio of (1) the original signal, (2) the quantized version of the amplitude-reduced signal, and (3) the quantized version of the amplitude-reduced signal after adding noise (dithering).\n",
        "1. Repeat Step 3 by setting *source* to 'music'.\n",
        "1. Change the constant *n_bits* to 4 and repeat Steps 3-5.\n",
        "1. Vary other variables to see their effect on the audio quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3_FXElmwWVy"
      },
      "source": [
        "## Answer the following questions\n",
        "1. When the signal amplitude is high enough (e.g., without any amplitude reduction), the quantized signal \"xq\" is perceptually close to the original signal \"x\" even at a bit depth of 8. Why is this the case?\n",
        "1. When the variable *amp_red_ratio* was set to 32, the quantized waveform \"yq\" did not look like the original waveform \"y\". Why is this the case?\n",
        "1. When the bit-depth is 4 (*n_bits = 4*), the quantization error becomes periodic. How will this kind of quantization error affect the audio quality of the quantized signal?\n",
        "1. Why does adding a small amount of noise to the signal that is vulnerable to quantization error help to reduce the detrimental effect of the quantization error?\n",
        "1. When *source* is set to 'tone', explain why severe quantization noise can change the perceptual frequency of the tone. You may check this phenomenon by listening to the audio of \"yq\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFbnLlwZYiej"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import numpy as np\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9okCotIYiek"
      },
      "outputs": [],
      "source": [
        "# Define some variables\n",
        "source = 'tone'            # Either 'tone' or 'music'\n",
        "use_colab = True            # Set to False if you use local IDE such as Visual Studio Code\n",
        "sr = 16000                  # Sampling rate of the target signal\n",
        "duration = 5                # Duration of the target signal\n",
        "n_bits = 8                  # Bit depth for the quantized signal\n",
        "amp_red_ratio= 32           # Reduce the amplitude of the signal by this factor\n",
        "noise_var_ratio = 20        # Noise ratio for dithering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSuIXyvHZ0q-"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive and create a folder for the lab exercise\n",
        "if use_colab == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  !mkdir -p /content/drive/MyDrive/Learning/EIE4435/Programs\n",
        "  %cd /content/drive/MyDrive/Learning/EIE4435/Programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCsCr5mpYiek"
      },
      "outputs": [],
      "source": [
        "# Function for plotting one frame of unquantized waveform, one frame of quantized waveform, and their spectrograms\n",
        "def plot_figure(x, xq, sr=16000, frm_len=512, hop_len=256):\n",
        "    '''\n",
        "    x: waveform\n",
        "    xq: quantized waveform\n",
        "    '''\n",
        "    e = xq - x\n",
        "    X = librosa.amplitude_to_db(np.abs(librosa.stft(x, n_fft=512, hop_length=256)), ref=np.max)  # STFT of x\n",
        "    Xq = librosa.amplitude_to_db(np.abs(librosa.stft(xq, n_fft=512, hop_length=256)), ref=np.max)  # STFT of xq\n",
        "    E = librosa.amplitude_to_db(np.abs(librosa.stft(e, n_fft=512, hop_length=256)), ref=np.max)  # STFT of e\n",
        "\n",
        "    _, ax = plt.subplots(nrows=3, sharex=True, figsize=(8,3))\n",
        "    smp_idx = range(2*frm_len, 3*frm_len)\n",
        "    librosa.display.waveshow(x[smp_idx], sr=sr, ax=ax[0])\n",
        "    ax[0].set_ylabel('x')\n",
        "    librosa.display.waveshow(xq[smp_idx], sr=sr, ax=ax[1])\n",
        "    ax[1].set_ylabel('xq')\n",
        "    librosa.display.waveshow(e[smp_idx], sr=sr, ax=ax[2])\n",
        "    ax[2].set_ylabel('e')\n",
        "    _, ax = plt.subplots(nrows=3, sharex=True, figsize=(8,3))\n",
        "    librosa.display.specshow(X, sr=sr, n_fft=frm_len, hop_length=hop_len, x_axis='time', y_axis='linear', ax=ax[0])\n",
        "    librosa.display.specshow(Xq, sr=sr, n_fft=frm_len, hop_length=hop_len, x_axis='time', y_axis='linear', ax=ax[1])\n",
        "    librosa.display.specshow(E, sr=sr, n_fft=frm_len, hop_length=hop_len, x_axis='time', y_axis='linear', ax=ax[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW5kBU-ZYiel"
      },
      "outputs": [],
      "source": [
        "# Function for performing quanitzation\n",
        "def quantize(y, n_bits=8, xmax=1):\n",
        "    Q = 2 * xmax/(2**n_bits)\n",
        "    yq = y/2 * (2**(n_bits-1) + 2**(n_bits-1) - 1)\n",
        "    yq = np.floor(yq).astype(int).astype(float)*Q\n",
        "    print(f\"{n_bits}-bit audio ranges from -{2**(n_bits - 1)*Q} to {(2**(n_bits - 1) - 1)*Q} for xmax={xmax} and Q={Q}\")\n",
        "    print(f\"Max quantized value: {np.max(yq)}, Avg quantized value: {np.mean(yq):.2f}\")\n",
        "    return yq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check a 3-bit quantizer with xmax=1\n",
        "y = np.array([-1, -0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8, 1.0])    # y ranges from -xmax to xmax\n",
        "yq = quantize(y, n_bits=3, xmax=1)\n",
        "np.set_printoptions(precision=2, floatmode='fixed')\n",
        "print(f\"y =  {y}\")\n",
        "print(f\"yq = {yq}\")\n",
        "print(f\"e =  {yq-y}\")"
      ],
      "metadata": {
        "id": "UtzcLSxq2UMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldosjE6gYiel"
      },
      "outputs": [],
      "source": [
        "if source == 'music':\n",
        "    # Load a wavefile and crop a 2-second segment from it\n",
        "    x, fs = librosa.load('../AudioFiles/Bach.mp3', mono=True, offset=0.0, duration=duration)\n",
        "    x = librosa.resample(x, orig_sr=fs, target_sr=sr)\n",
        "    x = ((x-np.min(x))/(np.max(x)-np.min(x))-0.5)*2\n",
        "else:\n",
        "    # Generate a tone of 500Hz with a sampling rate of 16kHz\n",
        "    x = librosa.tone(500, sr=sr, length=sr*2)\n",
        "    x = ((x-np.min(x))/(np.max(x)-np.min(x))-0.5)*2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOcduynYYiel"
      },
      "outputs": [],
      "source": [
        "xq = quantize(x, n_bits=n_bits)\n",
        "plot_figure(x, xq, sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NOoNcBCYiem"
      },
      "outputs": [],
      "source": [
        "# Reduce the amplitude of the signal to make it more vulnerable to quanization error.\n",
        "# Reduce the number of bits per sample\n",
        "y = x/amp_red_ratio\n",
        "yq = quantize(y, n_bits=n_bits, xmax=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omi6pc5mYien"
      },
      "outputs": [],
      "source": [
        "# Plot a short segment of the low-amplitude waveform, quantized waveform, quantization error, and their spectrograms\n",
        "plot_figure(y, yq, sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRm7LuIsYien"
      },
      "outputs": [],
      "source": [
        "# Perform dithering by adding Gaussian noise\n",
        "noise_var = np.max(np.abs(y))/noise_var_ratio         # Variance of Gaussian noise for dithering\n",
        "z = y + np.random.normal(0, noise_var, yq.shape[0])\n",
        "zq = quantize(z, n_bits=n_bits, xmax=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmbcAuv4Yien"
      },
      "outputs": [],
      "source": [
        "# Plot a frame of dithered signal, the quantization error, and their spectrograms\n",
        "plot_figure(z, zq, sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSroyX-QYien"
      },
      "outputs": [],
      "source": [
        "# Listen to the original waveform\n",
        "Audio(data=x, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvuOi57_wWV2"
      },
      "outputs": [],
      "source": [
        "# Listen to the quantized waveform (without amplitude reduction)\n",
        "Audio(data=xq, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtnDfVWKYien"
      },
      "outputs": [],
      "source": [
        "# Listen to the quantized waveform (with amplitude reduction)\n",
        "Audio(data=yq, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibY_7hCrYieo"
      },
      "outputs": [],
      "source": [
        "# Listen to the quantized waveform of the dithered signal (with amplitude reduction)\n",
        "Audio(data=zq, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf6f6iIWYieo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}